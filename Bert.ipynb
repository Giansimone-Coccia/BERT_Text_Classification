{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mfwTU32aAEJF","executionInfo":{"status":"ok","timestamp":1732551435842,"user_tz":-60,"elapsed":39006,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"198ee609-bb81-4630-be0c-c309ddc6c59a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","source":["!pip install pandas\n","!pip install transformers\n","!pip install torch\n","!pip install datasets\n","!pip install scikit-learn"],"metadata":{"id":"1cl8i-hJHN3G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732525166983,"user_tz":-60,"elapsed":14592,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"ee5e86fd-0a34-435c-9447-c42caf951d90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"]}]},{"cell_type":"markdown","source":["### ETL e caricamento dati"],"metadata":{"id":"dkHkr7G_KAwJ"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/reviews_0-250.csv')\n","\n","# Selezione delle colonne utili\n","dataset_10k = df[['review_text', 'is_recommended']]\n","\n","# Controlla valori mancanti\n","print(\"Valori nulli prima della rimozione:\")\n","print(dataset_10k.isnull().sum())\n","\n","# Rimuovi le righe con valori nulli (corretto)\n","dataset_finale = dataset_10k.dropna()\n","\n","# Conferma dimensioni finali del dataset\n","print(f\"Dimensioni finali del dataset dopo la rimozione: {dataset_finale.shape}\")\n","\n","# Verifica che non ci siano più valori nulli\n","print(\"Valori nulli dopo la rimozione:\")\n","print(dataset_finale.isnull().sum())\n","\n","dataset_finale.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"Eo8btq85ObIZ","executionInfo":{"status":"ok","timestamp":1732552670520,"user_tz":-60,"elapsed":10235,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"2c718c54-d7dd-4081-bc4c-c11f9909b416"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-edab6fb7373c>:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/reviews_0-250.csv')\n"]},{"output_type":"stream","name":"stdout","text":["Valori nulli prima della rimozione:\n","review_text          999\n","is_recommended    117486\n","dtype: int64\n","Dimensioni finali del dataset dopo la rimozione: (483645, 2)\n","Valori nulli dopo la rimozione:\n","review_text       0\n","is_recommended    0\n","dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["                                         review_text  is_recommended\n","0  I use this with the Nudestix “Citrus Clean Bal...             1.0\n","1  I bought this lip mask after reading the revie...             0.0\n","2  My review title says it all! I get so excited ...             1.0\n","3  I’ve always loved this formula for a long time...             1.0\n","4  If you have dry cracked lips, this is a must h...             1.0"],"text/html":["\n","  <div id=\"df-11a3f8f3-bbf9-4ed1-8c8e-f1c664838117\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_text</th>\n","      <th>is_recommended</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I use this with the Nudestix “Citrus Clean Bal...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I bought this lip mask after reading the revie...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>My review title says it all! I get so excited ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I’ve always loved this formula for a long time...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>If you have dry cracked lips, this is a must h...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11a3f8f3-bbf9-4ed1-8c8e-f1c664838117')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-11a3f8f3-bbf9-4ed1-8c8e-f1c664838117 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-11a3f8f3-bbf9-4ed1-8c8e-f1c664838117');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-313799df-191f-4b8c-b3b0-76f37ea99f82\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-313799df-191f-4b8c-b3b0-76f37ea99f82')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-313799df-191f-4b8c-b3b0-76f37ea99f82 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataset_finale"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Caricamento del dataset originale\n","df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/reviews_0-250.csv')\n","\n","# Selezione delle colonne utili\n","dataset = df[['review_text', 'is_recommended']]\n","\n","# Rimuovi le righe con valori nulli\n","dataset = dataset.dropna()\n","\n","# Suddividi le classi per `is_recommended`\n","class_1 = dataset[dataset['is_recommended'] == 1.0]\n","class_0 = dataset[dataset['is_recommended'] == 0.0]\n","\n","# Determina il numero di righe necessarie per bilanciare il dataset finale\n","num_samples_per_class = 5000\n","\n","# Preleva un numero uguale di campioni da entrambe le classi\n","balanced_class_1 = class_1.sample(n=num_samples_per_class, random_state=42)\n","balanced_class_0 = class_0.sample(n=num_samples_per_class, random_state=42)\n","\n","# Combina e mescola i dati bilanciati\n","balanced_dataset = pd.concat([balanced_class_1, balanced_class_0]).sample(frac=1, random_state=42)\n","\n","# Dividi il dataset bilanciato in 80% training, 10% validation e 10% testing\n","train_df, temp_df = train_test_split(balanced_dataset, test_size=0.2, random_state=42)\n","\n","# Ottieni gli indici dei dati di training\n","train_indices = train_df.index\n","\n","# Rimuovi i dati di training dal dataset originale\n","remaining_dataset = dataset.drop(index=train_indices)\n","\n","# Campiona 1,000 elementi per il set di validazione\n","val_df = remaining_dataset.sample(n=1000, random_state=42)\n","\n","# Rimuovi i dati di validazione dal dataset rimanente\n","remaining_dataset = remaining_dataset.drop(index=val_df.index)\n","\n","# Campiona 1,000 elementi per il set di test\n","test_df = remaining_dataset.sample(n=1000, random_state=42)\n","\n","# Verifica la suddivisione\n","print(f\"Validation set size: {len(val_df)}\")\n","print(f\"Test set size: {len(test_df)}\")\n","\n","# Verifica la suddivisione delle classi\n","print(f\"Training set - is_recommended = 1: {train_df['is_recommended'].value_counts().get(1.0, 0)}\")\n","print(f\"Training set - is_recommended = 0: {train_df['is_recommended'].value_counts().get(0.0, 0)}\")\n","print(f\"Validation set - is_recommended = 1: {val_df['is_recommended'].value_counts().get(1.0, 0)}\")\n","print(f\"Validation set - is_recommended = 0: {val_df['is_recommended'].value_counts().get(0.0, 0)}\")\n","print(f\"Test set - is_recommended = 1: {test_df['is_recommended'].value_counts().get(1.0, 0)}\")\n","print(f\"Test set - is_recommended = 0: {test_df['is_recommended'].value_counts().get(0.0, 0)}\")\n","\n","# Salva i dataset finali su file CSV\n","train_df.to_csv('/content/gdrive/MyDrive/Data science/Sephora/dataset/train_dataset.csv', index=False, encoding='utf-8')\n","val_df.to_csv('/content/gdrive/MyDrive/Data science/Sephora/dataset/val_dataset.csv', index=False, encoding='utf-8')\n","test_df.to_csv('/content/gdrive/MyDrive/Data science/Sephora/dataset/test_dataset.csv', index=False, encoding='utf-8')\n","\n","print(\"I dataset sono stati salvati!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nx9ZHxtrOKSK","executionInfo":{"status":"ok","timestamp":1732554414904,"user_tz":-60,"elapsed":5736,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"d05a4b32-3bca-4416-b4c7-803b0c30fbda"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-25-6f5e1b1c2a08>:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/reviews_0-250.csv')\n"]},{"output_type":"stream","name":"stdout","text":["Validation set size: 1000\n","Test set size: 1000\n","Training set - is_recommended = 1: 3987\n","Training set - is_recommended = 0: 4013\n","Validation set - is_recommended = 1: 838\n","Validation set - is_recommended = 0: 162\n","Test set - is_recommended = 1: 827\n","Test set - is_recommended = 0: 173\n","I dataset sono stati salvati!\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","import nltk\n","\n","# Se non l'hai già fatto, scarica le stopwords\n","nltk.download('stopwords')\n","sw = stopwords.words('english')\n","\n","def clean_text(text, remove_stopwords=False):\n","    \"\"\"\n","    Funzione per pulire il testo:\n","    - Rende il testo minuscolo\n","    - Rimuove URL, HTML, emoji e caratteri speciali\n","    - Opzionalmente rimuove stopwords\n","    \"\"\"\n","    # Converti in minuscolo\n","    text = text.lower()\n","\n","    # Rimuovi URL\n","    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n","\n","    # Rimuovi tag HTML\n","    html_pattern = re.compile(r'<.*?>')\n","    text = html_pattern.sub(r'', text)\n","\n","    # Rimuovi emoji\n","    emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\"\n","                               u\"\\U0001F300-\\U0001F5FF\"\n","                               u\"\\U0001F680-\\U0001F6FF\"\n","                               u\"\\U0001F1E0-\\U0001F1FF\"\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U000024C2-\\U0001F251\"\n","                               \"]+\", flags=re.UNICODE)\n","    text = emoji_pattern.sub(r'', text)\n","\n","    # Rimuovi caratteri speciali e numeri (mantieni punteggiatura utile)\n","    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n","\n","    # Opzione per rimuovere stopwords\n","    if remove_stopwords:\n","        text = \" \".join([word for word in text.split() if word not in sw])\n","\n","    # Rimuovi spazi extra\n","    text = text.strip()\n","\n","    return text\n","\n","\n","# Esegui la funzione di pulizia sul dataset\n","train_df['cleaned_review_text'] = train_df['review_text'].apply(lambda x: clean_text(x, remove_stopwords=True))\n","val_df['cleaned_review_text'] = val_df['review_text'].apply(lambda x: clean_text(x, remove_stopwords=True))\n","test_df['cleaned_review_text'] = test_df['review_text'].apply(lambda x: clean_text(x, remove_stopwords=True))\n","\n","# Visualizza i primi 5 esempi per verificare che la pulizia sia stata eseguita correttamente\n","print(train_df[['review_text', 'cleaned_review_text']].head())\n","print(val_df[['review_text', 'cleaned_review_text']].head())\n","print(test_df[['review_text', 'cleaned_review_text']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZqltSvpRGg9","executionInfo":{"status":"ok","timestamp":1732554509187,"user_tz":-60,"elapsed":3890,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"217bd392-5bf3-468f-9907-92c73bf2e5b2"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["                                              review_text  \\\n","437097  Muy buena crema para los ojos. La he estado us...   \n","405620  I haven’t experienced the pilling that other r...   \n","234224  I wanted to love this so bad but it made my ch...   \n","465293  I received the Clinique Wrinkle Correct Seurm ...   \n","523194  I like the Then I Met You Cleansing black WAAA...   \n","\n","                                      cleaned_review_text  \n","437097  muy buena crema para los ojos. la estado usand...  \n","405620  experienced pilling reviewers noted serum goes...  \n","234224  wanted love bad made chin jawline get small bu...  \n","465293  received clinique wrinkle correct seurm sample...  \n","523194  like met cleansing black waaay better. one gre...  \n","                                              review_text  \\\n","59550   Great clean. Soft scent. Doesn’t burn or dry o...   \n","68360   Meh, nothing special. Doesn’t do anything for ...   \n","583458  this saved my dry skin! my skin was so dry I c...   \n","254131  I have dry skin and this moisturizer is AMAZIN...   \n","6474    I live in a cold dry place so I desperately ne...   \n","\n","                                      cleaned_review_text  \n","59550             great clean. soft scent. burn dry skin.  \n","68360   meh, nothing special. anything me. another med...  \n","583458  saved dry skin! skin dry put makeup face! slat...  \n","254131  dry skin moisturizer amazing. leaves skin feel...  \n","6474    live cold dry place desperately need chapstick...  \n","                                              review_text  \\\n","220709  The best primer/sunscreen for all ages.  I use...   \n","182591  I received this product as a free sample from ...   \n","221368  I have combo/oily sensitive acne-prone skin an...   \n","417934  In the winter my lips are always so chapped no...   \n","313503  Given the great reviews and the fact that I lo...   \n","\n","                                      cleaned_review_text  \n","220709  best primer sunscreen ages. use year old daugh...  \n","182591  received product free sample pinchme. really g...  \n","221368  combo oily sensitive acne prone skin tried eve...  \n","417934  winter lips always chapped matter lip product ...  \n","313503  given great reviews fact love tatcha, high exp...  \n"]}]},{"cell_type":"markdown","source":["### Addestramento"],"metadata":{"id":"eKMOqP-FTpnI"}},{"cell_type":"code","source":["import pandas as pd\n","\n","train_df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/dataset/train_dataset.csv')\n","val_df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/dataset/val_dataset.csv')\n","test_df = pd.read_csv('/content/gdrive/MyDrive/Data science/Sephora/dataset/test_dataset.csv')"],"metadata":{"id":"H27Oyj34hm05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","import torch\n","\n","# Carica il tokenizer pre-addestrato di BERT\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Funzione per tokenizzare il testo e convertire in tensori (in batch)\n","def tokenize_text_batch(texts, max_length=512):\n","    encoding = tokenizer.batch_encode_plus(\n","        texts,\n","        padding=True,\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors=\"pt\"\n","    )\n","    return encoding['input_ids'], encoding['attention_mask']\n","\n","# Prepara i dati per BERT\n","def prepare_data(df, tokenizer, max_length=512):\n","    input_ids, attention_masks = tokenize_text_batch(df['review_text'].tolist(), max_length)\n","    return input_ids, attention_masks\n","\n","# Prepara i target (rating e is_recommended)\n","def prepare_targets(df):\n","    recommended = df['is_recommended'].values\n","    return torch.tensor(recommended)\n","\n","# Prepara i dati di training, validation e test\n","train_inputs, train_masks = prepare_data(train_df, tokenizer)\n","val_inputs, val_masks = prepare_data(val_df, tokenizer)\n","test_inputs, test_masks = prepare_data(test_df, tokenizer)\n","\n","train_recommendations = prepare_targets(train_df)\n","val_recommendations = prepare_targets(val_df)\n","test_recommendations = prepare_targets(test_df)"],"metadata":{"id":"dASqvbnYTr-r","executionInfo":{"status":"ok","timestamp":1732554920843,"user_tz":-60,"elapsed":19487,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification\n","import torch.nn as nn\n","\n","class BERTClassificationModel(nn.Module):\n","    def __init__(self, model_name='bert-base-uncased', num_classes=2):\n","        super(BERTClassificationModel, self).__init__()\n","\n","        # Carica il modello BERT pre-addestrato per classificazione binaria\n","        self.bert = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n","\n","        # Dropout per evitare overfitting\n","        self.dropout = nn.Dropout(0.3)\n","\n","    def forward(self, input_ids, attention_mask):\n","        # Passa attraverso BERT\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        # Usa i logits per la classificazione binaria\n","        class_preds = output.logits  # Predizione per la classificazione binaria (is_recommended)\n","\n","        return class_preds"],"metadata":{"id":"hVLwbO5rTyh3","executionInfo":{"status":"ok","timestamp":1732554942267,"user_tz":-60,"elapsed":13534,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from torch.optim import AdamW\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score\n","import torch\n","\n","# Creare i DataLoader per training e validation (solo con 'is_recommended')\n","train_data = TensorDataset(train_inputs, train_masks, train_recommendations)\n","val_data = TensorDataset(val_inputs, val_masks, val_recommendations)\n","\n","train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n","val_dataloader = DataLoader(val_data, batch_size=8, shuffle=False)\n","\n","# Verifica se la GPU è disponibile\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Inizializza il modello (solo classificazione binaria)\n","model = BERTClassificationModel()\n","model.to(device)  # Sposta il modello sulla GPU (o CPU)\n","\n","# Impostiamo l'ottimizzatore\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","\n","# Impostiamo la loss function\n","classification_loss_fn = nn.CrossEntropyLoss()  # CrossEntropyLoss per classificazione multi-classe (binaria con 2 classi)\n","# Modifica la funzione di addestramento\n","def train_model(model, train_dataloader, val_dataloader, optimizer, epochs=3):\n","    model.train()\n","\n","    best_val_loss = float('inf')  # Inizializza la miglior perdita di validazione come infinita\n","    for epoch in range(epochs):\n","        total_train_loss = 0\n","\n","        # Training phase\n","        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n","            optimizer.zero_grad()\n","\n","            input_ids, attention_mask, recommendations = batch\n","\n","            # Sposta i tensori sulla GPU (se disponibile)\n","            input_ids, attention_mask, recommendations = input_ids.to(device), attention_mask.to(device), recommendations.to(device)\n","\n","            # Assicurati che i target siano di tipo long (interi) per CrossEntropyLoss\n","            recommendations = recommendations.to(torch.long)  # CrossEntropyLoss richiede target come long tensor\n","\n","            # Passa attraverso il modello\n","            class_preds = model(input_ids, attention_mask)\n","\n","            # Calcola la perdita per la classificazione binaria\n","            class_loss = classification_loss_fn(class_preds.view(-1, 2), recommendations)\n","\n","            # Perdita totale\n","            total_loss = class_loss\n","            total_loss.backward()\n","\n","            optimizer.step()\n","            total_train_loss += total_loss.item()\n","\n","        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_train_loss / len(train_dataloader)}\")\n","\n","        # Fase di validazione\n","        val_loss, val_accuracy, val_f1 = evaluate_model(model, val_dataloader)\n","\n","        print(f\"Epoch {epoch+1}/{epochs} - Validation Loss: {val_loss}\")\n","        print(f\"Epoch {epoch+1}/{epochs} - Validation Accuracy: {val_accuracy}\")\n","        print(f\"Epoch {epoch+1}/{epochs} - Validation F1: {val_f1}\")\n","\n","        # Se la perdita di validazione è la più bassa, salva il modello\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), 'best_model.pth')  # Salva il modello con la miglior perdita di validazione\n","            print(\"Model saved!\")\n","\n","# Funzione per la fase di valutazione\n","def evaluate_model(model, val_dataloader):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():  # Disabilita il calcolo del gradiente durante la valutazione\n","        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n","            input_ids, attention_mask, recommendations = batch\n","\n","            input_ids, attention_mask, recommendations = input_ids.to(device), attention_mask.to(device), recommendations.to(device)\n","            recommendations = recommendations.to(torch.long)\n","\n","            # Passa attraverso il modello\n","            class_preds = model(input_ids, attention_mask)\n","\n","            # Calcola la perdita\n","            class_loss = classification_loss_fn(class_preds.view(-1, 2), recommendations)\n","            total_loss += class_loss.item()\n","\n","            # Salva le predizioni e le etichette per calcolare accuracy e F1-score\n","            _, preds = torch.max(class_preds, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(recommendations.cpu().numpy())\n","\n","    # Calcola l'accuracy e la F1-score\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds)\n","\n","    return total_loss / len(val_dataloader), accuracy, f1\n","\n","# Esegui l'addestramento\n","train_model(model, train_dataloader, val_dataloader, optimizer, epochs=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvAxRb6XT6sf","executionInfo":{"status":"ok","timestamp":1732560235020,"user_tz":-60,"elapsed":2288530,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"38da7718-cf26-4306-cb51-edcb2166bf08"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3 - Training: 100%|██████████| 1000/1000 [12:25<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3 - Train Loss: 0.27512861247733233\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 125/125 [00:27<00:00,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3 - Validation Loss: 0.16875295297056436\n","Epoch 1/3 - Validation Accuracy: 0.938\n","Epoch 1/3 - Validation F1: 0.9620098039215687\n","Model saved!\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3 - Training: 100%|██████████| 1000/1000 [12:08<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3 - Train Loss: 0.10971858622482977\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 125/125 [00:27<00:00,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3 - Validation Loss: 0.1706325111463666\n","Epoch 2/3 - Validation Accuracy: 0.938\n","Epoch 2/3 - Validation F1: 0.9621951219512195\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3 - Training: 100%|██████████| 1000/1000 [12:08<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3 - Train Loss: 0.04935084867989645\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 125/125 [00:27<00:00,  4.50it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3 - Validation Loss: 0.16975996348727496\n","Epoch 3/3 - Validation Accuracy: 0.937\n","Epoch 3/3 - Validation F1: 0.9614206981016534\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Salvare l'intero modello\n","torch.save(model, '/content/gdrive/MyDrive/Data science/Sephora/modello/BERT_v1_full.pth')"],"metadata":{"id":"JjEFv-cjeUcH","executionInfo":{"status":"ok","timestamp":1732557618661,"user_tz":-60,"elapsed":2243,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Creare il DataLoader per il test set (solo con 'is_recommended')\n","test_data = TensorDataset(test_inputs, test_masks, test_recommendations)\n","test_dataloader = DataLoader(test_data, batch_size=16, shuffle=False)\n","\n","def evaluate_model(model, test_dataloader):\n","    model.eval()  # Setta il modello in modalità valutazione\n","    total_test_loss = 0\n","    correct_classifications = 0\n","    total_classifications = 0\n","\n","    all_recommendations = []\n","    all_class_preds = []\n","\n","    with torch.no_grad():\n","        for batch in test_dataloader:\n","            input_ids, attention_mask, recommendations = batch\n","\n","            # Trasferisci i tensori su GPU (se disponibile)\n","            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n","            recommendations = recommendations.to(device).to(torch.long)\n","\n","            # Passa attraverso il modello\n","            class_preds = model(input_ids, attention_mask)\n","\n","            # Calcola la perdita per la classificazione\n","            class_loss = classification_loss_fn(class_preds.view(-1, 2), recommendations)\n","            total_test_loss += class_loss.item()\n","\n","            # Calcola accuratezza per classificazione\n","            preds_class = torch.argmax(class_preds, dim=1)\n","            correct_classifications += (preds_class == recommendations).sum().item()\n","            total_classifications += len(recommendations)\n","\n","            # Salva i risultati per le metriche\n","            all_recommendations.extend(recommendations.cpu().numpy())\n","            all_class_preds.extend(preds_class.cpu().numpy())\n","\n","    # Calcola metrica per classificazione\n","    accuracy = correct_classifications / total_classifications\n","    print(f\"Test Loss: {total_test_loss / len(test_dataloader)}\")\n","    print(f\"Test Accuracy for is_recommended: {accuracy}\")\n","\n","    # Report per classificazione\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(all_recommendations, all_class_preds, target_names=[\"Not Recommended\", \"Recommended\"]))\n","\n","# Chiamata alla funzione\n","evaluate_model(model, test_dataloader)"],"metadata":{"id":"--WNovn6T9ku","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732560321228,"user_tz":-60,"elapsed":28841,"user":{"displayName":"Giulio Piercecchi","userId":"03299155448107628680"}},"outputId":"b93f040e-0663-445b-d8f0-c98c1632b033"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.187448073322663\n","Test Accuracy for is_recommended: 0.938\n","\n","Classification Report:\n","                 precision    recall  f1-score   support\n","\n","Not Recommended       0.75      0.95      0.84       173\n","    Recommended       0.99      0.93      0.96       827\n","\n","       accuracy                           0.94      1000\n","      macro avg       0.87      0.94      0.90      1000\n","   weighted avg       0.95      0.94      0.94      1000\n","\n"]}]}]}